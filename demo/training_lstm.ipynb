{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913afcd2-a55e-4804-adf4-699a3f3a660a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1edf9e-da30-42bb-9bf4-ade44cf3afd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4635e3f-8a34-48ac-b4f5-d871bdfcda0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from hython.datasets.datasets import get_dataset\n",
    "from hython.trainer import train_val\n",
    "from hython.sampler import SamplerBuilder, RegularIntervalDownsampler\n",
    "from hython.metrics import MSEMetric\n",
    "from hython.losses import RMSELoss\n",
    "from hython.utils import read_from_zarr, set_seed\n",
    "from hython.models.cudnnLSTM import CuDNNLSTM\n",
    "from hython.trainer import RNNTrainer, RNNTrainParams\n",
    "from hython.normalizer import Normalizer\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a78cf5-bd72-4a3d-bd18-ce49d0e8fdee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3186025-caa2-429f-88da-8c9c6b23c292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT  = \"exp1\"\n",
    "\n",
    "SURROGATE_INPUT = \"https://eurac-eo.s3.amazonaws.com/INTERTWIN/SURROGATE_INPUT/adg1km_eobs_preprocessed.zarr/\"\n",
    "\n",
    "SURROGATE_MODEL_OUTPUT = f\"path/to/model/output/directory/{EXPERIMENT}.pt\"\n",
    "\n",
    "TMP_STATS = \"path/to/temporary/stats/directory\" \n",
    "\n",
    "# === FILTER ==============================================================\n",
    "\n",
    "# train/test temporal range\n",
    "train_temporal_range = slice(\"2012-01-01\",\"2018-12-31\")\n",
    "test_temporal_range = slice(\"2019-01-01\", \"2019-12-31\")\n",
    "\n",
    "# variables\n",
    "dynamic_names = [\"precip\", \"pet\", \"temp\"] \n",
    "static_names = [ \"thetaS\", \"thetaR\", \"KsatVer\", \"SoilThickness\", \"RootingDepth\", \"f\", \"Swood\", \"Sl\", \"Kext\"]\n",
    "target_names = [\"vwc\", \"actevap\"]# [\"vwc\", \"actevap\", \"snow\", \"snowwater\"] \n",
    "\n",
    "# === MASK ========================================================================================\n",
    "\n",
    "mask_names = [\"mask_missing\", \"mask_lake\"] # names depends on preprocessing application\n",
    "\n",
    "# === DATASET ========================================================================================\n",
    "\n",
    "DATASET = \"LSTMDataset\"\n",
    "\n",
    "# == MODEL  ========================================================================================\n",
    "\n",
    "HIDDEN_SIZE = 24\n",
    "DYNAMIC_INPUT_SIZE = len(dynamic_names)\n",
    "STATIC_INPUT_SIZE = len(static_names)\n",
    "OUTPUT_SIZE = len(target_names)\n",
    "\n",
    "TARGET_WEIGHTS = {t:1/len(target_names) for t in target_names}\n",
    "\n",
    "\n",
    "# === SAMPLER/TRAINER ===================================================================================\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH = 256\n",
    "SEED = 42\n",
    "\n",
    "# downsampling, speeds up the training!\n",
    "\n",
    "# - spatial\n",
    "\n",
    "DONWSAMPLING = False\n",
    "TRAIN_INTERVAL = [3,3]\n",
    "TRAIN_ORIGIN = [0,0]\n",
    "\n",
    "TEST_INTERVAL = [3,3]\n",
    "TEST_ORIGIN = [2,2]\n",
    "\n",
    "# - temporal\n",
    "TEMPORAL_SUBSAMPLING = True\n",
    "TEMPORAL_SUBSET = [150, 150] # n of sequences \n",
    "SEQ_LENGTH = 360\n",
    "\n",
    "\n",
    "assert sum(v for v in TARGET_WEIGHTS.values()) == 1, \"check target weights\"\n",
    "TARGET_INITIALS = \"\".join([i[0].capitalize() for i in target_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c67bf4f-55e3-46fc-927b-72711d831f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221b3d8f-3c17-4b4b-bd85-8cfc1c765f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xd = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"xd\", multi_index=\"gridcell\")\n",
    "    .sel(time=train_temporal_range)\n",
    "    .xd.sel(feat=dynamic_names)\n",
    ")\n",
    "Xs = read_from_zarr(url=SURROGATE_INPUT, group=\"xs\", multi_index=\"gridcell\").xs.sel(\n",
    "    feat=static_names\n",
    ")\n",
    "Y = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"y\", multi_index=\"gridcell\")\n",
    "    .sel(time=train_temporal_range)\n",
    "    .y.sel(feat=target_names)\n",
    ")\n",
    "\n",
    "SHAPE = Xd.attrs[\"shape\"]\n",
    "\n",
    "\n",
    "# === READ TEST ===================================================================\n",
    "\n",
    "Y_test = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"y\", multi_index=\"gridcell\")\n",
    "    .sel(time=test_temporal_range)\n",
    "    .y.sel(feat=target_names)\n",
    ")\n",
    "Xd_test = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"xd\", multi_index=\"gridcell\")\n",
    "    .sel(time=test_temporal_range)\n",
    "    .xd.sel(feat=dynamic_names)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314c3596-a997-4b68-a94e-e7b48c3267e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"mask\")\n",
    "    .mask.sel(mask_layer=mask_names)\n",
    "    .any(dim=\"mask_layer\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f6c0de-d71a-430b-91fc-52fff2d259b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DONWSAMPLING:\n",
    "    train_downsampler = RegularIntervalDownsampler(\n",
    "        intervals=TRAIN_INTERVAL, origin=TRAIN_ORIGIN\n",
    "    )       \n",
    "    test_downsampler = RegularIntervalDownsampler(\n",
    "        intervals=TEST_INTERVAL, origin=TEST_ORIGIN\n",
    "    )\n",
    "else:\n",
    "    train_downsampler, test_downsampler = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419b87d9-a610-4933-8fd1-6579aefbc99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_dynamic = Normalizer(method=\"standardize\",\n",
    "                                type=\"spacetime\", axis_order=\"NTC\")\n",
    "normalizer_static = Normalizer(method=\"standardize\",\n",
    "                               type=\"space\", axis_order=\"NTC\")\n",
    "normalizer_target = Normalizer(method=\"standardize\", type=\"spacetime\",\n",
    "                               axis_order=\"NTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de2a80e-82c1-4845-9b30-58fe6da906e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(DATASET)(\n",
    "        Xd,\n",
    "        Y,\n",
    "        Xs,\n",
    "        original_domain_shape=SHAPE,\n",
    "        mask=masks,\n",
    "        downsampler=train_downsampler,\n",
    "        normalizer_dynamic=normalizer_dynamic,\n",
    "        normalizer_static=normalizer_static,\n",
    "        normalizer_target=normalizer_target\n",
    ")\n",
    "test_dataset = get_dataset(DATASET)(\n",
    "        Xd_test,\n",
    "        Y_test,\n",
    "        Xs,\n",
    "        original_domain_shape=SHAPE,\n",
    "        mask=masks,\n",
    "        downsampler=test_downsampler,\n",
    "        normalizer_dynamic=normalizer_dynamic,\n",
    "        normalizer_static=normalizer_static,\n",
    "        normalizer_target=normalizer_target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116051fc-240e-4b1e-bc30-556b6dfa0956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === SAMPLER ===================================================================\n",
    "\n",
    "\n",
    "train_sampler_builder = SamplerBuilder(\n",
    "    train_dataset,\n",
    "    sampling=\"random\", \n",
    "    processing=\"single-gpu\")\n",
    "\n",
    "test_sampler_builder = SamplerBuilder(\n",
    "    test_dataset,\n",
    "    sampling=\"sequential\", \n",
    "    processing=\"single-gpu\")\n",
    "\n",
    "\n",
    "train_sampler = train_sampler_builder.get_sampler()\n",
    "test_sampler = test_sampler_builder.get_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b29ef9da-180f-4ed5-b663-63a971d2ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA LOADER ===================================================================\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH , sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH , sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c2923c-37a4-4a9a-8a75-d0d81a9e785e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDNNLSTM(\n",
       "  (fc0): Linear(in_features=12, out_features=24, bias=True)\n",
       "  (lstm): LSTM(24, 24, batch_first=True)\n",
       "  (fc1): Linear(in_features=24, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === MODEL ===================================================================\n",
    "\n",
    "model = CuDNNLSTM(\n",
    "                hidden_size=HIDDEN_SIZE, \n",
    "                dynamic_input_size=DYNAMIC_INPUT_SIZE,\n",
    "                static_input_size=STATIC_INPUT_SIZE, \n",
    "                output_size=OUTPUT_SIZE\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f95b1c0-d930-4678-ac9e-6f473e7c6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=10)\n",
    "\n",
    "loss_fn = RMSELoss(target_weight=TARGET_WEIGHTS)\n",
    "metric_fn = MSEMetric(target_names=target_names)\n",
    "\n",
    "trainer = RNNTrainer(\n",
    "    RNNTrainParams(\n",
    "            experiment=EXPERIMENT,\n",
    "            temporal_subsampling=TEMPORAL_SUBSAMPLING, \n",
    "            temporal_subset=TEMPORAL_SUBSET, \n",
    "            seq_length=SEQ_LENGTH, \n",
    "            target_names=target_names,\n",
    "            metric_func=metric_fn,\n",
    "            loss_func=loss_fn)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7caaa8-b241-46fa-8235-a991062ef986",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_history, metric_history = train_val(\n",
    "    trainer,\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    opt,\n",
    "    lr_scheduler,\n",
    "    SURROGATE_MODEL_OUTPUT,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c0feb-1a0b-4b7d-8746-b0d8c169e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lepochs = list(range(1, EPOCHS + 1))\n",
    "\n",
    "fig, axs = plt.subplots(len(target_names) +1, 1, figsize= (12,10), sharex=True)\n",
    "\n",
    "axs[0].plot(lepochs, [i.detach().cpu().numpy() for i in loss_history['train']], marker='.', linestyle='-', color='b', label='Training')\n",
    "axs[0].plot(lepochs, [i.detach().cpu().numpy() for i in loss_history['val']], marker='.', linestyle='-', color='r', label='Validation')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_ylabel(loss_fn.__name__)\n",
    "axs[0].grid(True)\n",
    "axs[0].legend(bbox_to_anchor=(1,1))\n",
    "\n",
    "for i, variable in enumerate(target_names):\n",
    "    axs[i+1].plot(lepochs, metric_history[f'train_{variable}'], marker='.', linestyle='-', color='b', label='Training')\n",
    "    axs[i+1].plot(lepochs, metric_history[f'val_{variable}'], marker='.', linestyle='-', color='r', label='Validation')\n",
    "    axs[i+1].set_title(variable)\n",
    "    axs[i+1].set_ylabel(metric_fn.__class__.__name__)\n",
    "    axs[i+1].grid(True)\n",
    "    axs[i+1].legend(bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcdfd81-ea31-40d6-90fd-117ed50f233a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a275b19-8ba6-46a0-afd7-8055e88f32fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-hython",
   "language": "python",
   "name": "test-hython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
